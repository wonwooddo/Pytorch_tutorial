{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/wonwooddo/Pytorch_tutorial/blob/master/04.utils_tensorboard.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "PWEsDAXeg3cS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "73ce2dfb-3b33-4294-882d-fbf52ee0edd1"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install Pillow==4.0.0\n",
        "!pip install PIL\n",
        "!pip install image\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python2.7/dist-packages (0.4.0)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python2.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from torchvision) (1.14.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python2.7/dist-packages (from torchvision) (0.4.0)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "  Using cached https://files.pythonhosted.org/packages/00/49/a0483e7308b4b04b5a898789911dbb876d9fea54e7df0453915e47744cfd/Pillow-5.1.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.1.0\n",
            "Collecting Pillow==4.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/89/99/0e3522a9764fe371bf9f7729404b1ef7d9c4fc49cbe5f1761c6e07812345/Pillow-4.0.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python2.7/dist-packages (from Pillow==4.0.0) (0.45.1)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.1.0\n",
            "    Uninstalling Pillow-5.1.0:\n",
            "      Successfully uninstalled Pillow-5.1.0\n",
            "Successfully installed Pillow-4.0.0\n",
            "Collecting PIL\n",
            "\u001b[31m  Could not find a version that satisfies the requirement PIL (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for PIL\u001b[0m\n",
            "Requirement already satisfied: image in /usr/local/lib/python2.7/dist-packages (1.5.24)\n",
            "Requirement already satisfied: django in /usr/local/lib/python2.7/dist-packages (from image) (1.11.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python2.7/dist-packages (from image) (4.0.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python2.7/dist-packages (from django->image) (2018.4)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python2.7/dist-packages (from pillow->image) (0.45.1)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J6OqsLybxEsm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import PIL.Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wxUrma6bLuzk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import scipy.misc \n",
        "try:\n",
        "    from StringIO import StringIO  # Python 2.7\n",
        "except ImportError:\n",
        "    from io import BytesIO         # Python 3.x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-b5Kv8KdrNwq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Logger(object):\n",
        "    \n",
        "    def __init__(self, log_dir):\n",
        "        \"\"\"Create a summary writer logging to log_dir.\"\"\"\n",
        "        self.writer = tf.summary.FileWriter(log_dir)\n",
        "\n",
        "    def scalar_summary(self, tag, value, step):\n",
        "        \"\"\"Log a scalar variable.\"\"\"\n",
        "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
        "        self.writer.add_summary(summary, step)\n",
        "\n",
        "    def image_summary(self, tag, images, step):\n",
        "        \"\"\"Log a list of images.\"\"\"\n",
        "\n",
        "        img_summaries = []\n",
        "        for i, img in enumerate(images):\n",
        "            # Write the image to a string\n",
        "            try:\n",
        "                s = StringIO()\n",
        "            except:\n",
        "                s = BytesIO()\n",
        "            scipy.misc.toimage(img).save(s, format=\"png\")\n",
        "\n",
        "            # Create an Image object\n",
        "            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n",
        "                                       height=img.shape[0],\n",
        "                                       width=img.shape[1])\n",
        "            # Create a Summary value\n",
        "            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
        "\n",
        "        # Create and write Summary\n",
        "        summary = tf.Summary(value=img_summaries)\n",
        "        self.writer.add_summary(summary, step)\n",
        "        \n",
        "    def histo_summary(self, tag, values, step, bins=1000):\n",
        "        \"\"\"Log a histogram of the tensor of values.\"\"\"\n",
        "\n",
        "        # Create a histogram using numpy\n",
        "        counts, bin_edges = np.histogram(values, bins=bins)\n",
        "\n",
        "        # Fill the fields of the histogram proto\n",
        "        hist = tf.HistogramProto()\n",
        "        hist.min = float(np.min(values))\n",
        "        hist.max = float(np.max(values))\n",
        "        hist.num = int(np.prod(values.shape))\n",
        "        hist.sum = float(np.sum(values))\n",
        "        hist.sum_squares = float(np.sum(values**2))\n",
        "\n",
        "        # Drop the start of the first bin\n",
        "        bin_edges = bin_edges[1:]\n",
        "\n",
        "        # Add bin edges and counts\n",
        "        for edge in bin_edges:\n",
        "            hist.bucket_limit.append(edge)\n",
        "        for c in counts:\n",
        "            hist.bucket.append(c)\n",
        "\n",
        "        # Create and write Summary\n",
        "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n",
        "        self.writer.add_summary(summary, step)\n",
        "        self.writer.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S7NIL4gzsiso",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# MNIST dataset \n",
        "dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                     train=True, \n",
        "                                     transform=transforms.ToTensor(),  \n",
        "                                     download=True)\n",
        "\n",
        "# Data loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
        "                                          batch_size=100, \n",
        "                                          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rX12-v_2sp9r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size=784, hidden_size=500, num_classes=10):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "model = NeuralNet().to(device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PlRrJnYistWQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logger = Logger('./logs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XSsy7uhpsu04",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HmeEFiOZwr2E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def register_extension(id, extension):\n",
        "    PIL.Image.EXTENSION[extension.lower()] = id.upper()\n",
        "PIL.Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions):\n",
        "    for extension in extensions:\n",
        "        register_extension(id, extension)\n",
        "PIL.Image.register_extensions = register_extensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iBuYozPXtsFF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_iter = iter(data_loader)\n",
        "iter_per_epoch = len(data_loader)\n",
        "total_step = 50000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pPDPGuDttysu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8117
        },
        "outputId": "6fb33ddf-3c19-4fde-94d9-a441b99f4f34"
      },
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "for step in range(total_step):\n",
        "    \n",
        "    # Reset the data_iter\n",
        "    if (step+1) % iter_per_epoch == 0:\n",
        "        data_iter = iter(data_loader)\n",
        "\n",
        "    # Fetch images and labels\n",
        "    images, labels = next(data_iter)\n",
        "    images, labels = images.view(images.size(0), -1).to(device), labels.to(device)\n",
        "    \n",
        "    # Forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Compute accuracy\n",
        "    _, argmax = torch.max(outputs, 1)\n",
        "    accuracy = (labels == argmax.squeeze()).float().mean()\n",
        "\n",
        "    if (step+1) % 100 == 0:\n",
        "        print ('Step [{}/{}], Loss: {:.4f}, Acc: {:.2f}' \n",
        "               .format(step+1, total_step, loss.item(), accuracy.item()))\n",
        "\n",
        "        # ================================================================== #\n",
        "        #                        Tensorboard Logging                         #\n",
        "        # ================================================================== #\n",
        "\n",
        "        # 1. Log scalar values (scalar summary)\n",
        "        info = { 'loss': loss.item(), 'accuracy': accuracy.item() }\n",
        "\n",
        "        for tag, value in info.items():\n",
        "            logger.scalar_summary(tag, value, step+1)\n",
        "\n",
        "        # 2. Log values and gradients of the parameters (histogram summary)\n",
        "        for tag, value in model.named_parameters():\n",
        "            tag = tag.replace('.', '/')\n",
        "            logger.histo_summary(tag, value.data.cpu().numpy(), step+1)\n",
        "            logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), step+1)\n",
        "\n",
        "        # 3. Log training images (image summary)\n",
        "        info = { 'images': images.view(-1, 28, 28)[:10].cpu().numpy() }\n",
        "\n",
        "        for tag, images in info.items():\n",
        "            logger.image_summary(tag, images, step+1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step [100/50000], Loss: 2.1866, Acc: 0.45\n",
            "Step [200/50000], Loss: 2.0479, Acc: 0.74\n",
            "Step [300/50000], Loss: 1.9544, Acc: 0.73\n",
            "Step [400/50000], Loss: 1.8005, Acc: 0.77\n",
            "Step [500/50000], Loss: 1.6497, Acc: 0.82\n",
            "Step [600/50000], Loss: 1.5552, Acc: 0.79\n",
            "Step [700/50000], Loss: 1.4571, Acc: 0.80\n",
            "Step [800/50000], Loss: 1.3430, Acc: 0.74\n",
            "Step [900/50000], Loss: 1.1478, Acc: 0.84\n",
            "Step [1000/50000], Loss: 1.1634, Acc: 0.82\n",
            "Step [1100/50000], Loss: 1.0487, Acc: 0.85\n",
            "Step [1200/50000], Loss: 0.9536, Acc: 0.86\n",
            "Step [1300/50000], Loss: 0.9910, Acc: 0.80\n",
            "Step [1400/50000], Loss: 0.8658, Acc: 0.84\n",
            "Step [1500/50000], Loss: 0.9392, Acc: 0.82\n",
            "Step [1600/50000], Loss: 0.8197, Acc: 0.87\n",
            "Step [1700/50000], Loss: 0.8122, Acc: 0.80\n",
            "Step [1800/50000], Loss: 0.7955, Acc: 0.82\n",
            "Step [1900/50000], Loss: 0.6013, Acc: 0.90\n",
            "Step [2000/50000], Loss: 0.7255, Acc: 0.88\n",
            "Step [2100/50000], Loss: 0.6816, Acc: 0.85\n",
            "Step [2200/50000], Loss: 0.7022, Acc: 0.81\n",
            "Step [2300/50000], Loss: 0.6438, Acc: 0.85\n",
            "Step [2400/50000], Loss: 0.7266, Acc: 0.82\n",
            "Step [2500/50000], Loss: 0.5794, Acc: 0.85\n",
            "Step [2600/50000], Loss: 0.5733, Acc: 0.89\n",
            "Step [2700/50000], Loss: 0.5691, Acc: 0.87\n",
            "Step [2800/50000], Loss: 0.5184, Acc: 0.89\n",
            "Step [2900/50000], Loss: 0.4865, Acc: 0.92\n",
            "Step [3000/50000], Loss: 0.4381, Acc: 0.92\n",
            "Step [3100/50000], Loss: 0.5059, Acc: 0.91\n",
            "Step [3200/50000], Loss: 0.5166, Acc: 0.86\n",
            "Step [3300/50000], Loss: 0.4783, Acc: 0.87\n",
            "Step [3400/50000], Loss: 0.6050, Acc: 0.87\n",
            "Step [3500/50000], Loss: 0.4198, Acc: 0.90\n",
            "Step [3600/50000], Loss: 0.4946, Acc: 0.89\n",
            "Step [3700/50000], Loss: 0.4939, Acc: 0.85\n",
            "Step [3800/50000], Loss: 0.3885, Acc: 0.91\n",
            "Step [3900/50000], Loss: 0.3262, Acc: 0.97\n",
            "Step [4000/50000], Loss: 0.4762, Acc: 0.88\n",
            "Step [4100/50000], Loss: 0.4028, Acc: 0.91\n",
            "Step [4200/50000], Loss: 0.3844, Acc: 0.92\n",
            "Step [4300/50000], Loss: 0.4867, Acc: 0.85\n",
            "Step [4400/50000], Loss: 0.4259, Acc: 0.91\n",
            "Step [4500/50000], Loss: 0.4597, Acc: 0.88\n",
            "Step [4600/50000], Loss: 0.4248, Acc: 0.88\n",
            "Step [4700/50000], Loss: 0.3671, Acc: 0.92\n",
            "Step [4800/50000], Loss: 0.3538, Acc: 0.94\n",
            "Step [4900/50000], Loss: 0.3588, Acc: 0.89\n",
            "Step [5000/50000], Loss: 0.5329, Acc: 0.84\n",
            "Step [5100/50000], Loss: 0.3242, Acc: 0.92\n",
            "Step [5200/50000], Loss: 0.5295, Acc: 0.86\n",
            "Step [5300/50000], Loss: 0.3602, Acc: 0.88\n",
            "Step [5400/50000], Loss: 0.5940, Acc: 0.81\n",
            "Step [5500/50000], Loss: 0.2925, Acc: 0.93\n",
            "Step [5600/50000], Loss: 0.3618, Acc: 0.90\n",
            "Step [5700/50000], Loss: 0.2857, Acc: 0.92\n",
            "Step [5800/50000], Loss: 0.4245, Acc: 0.89\n",
            "Step [5900/50000], Loss: 0.3231, Acc: 0.90\n",
            "Step [6000/50000], Loss: 0.3647, Acc: 0.89\n",
            "Step [6100/50000], Loss: 0.3545, Acc: 0.92\n",
            "Step [6200/50000], Loss: 0.3474, Acc: 0.90\n",
            "Step [6300/50000], Loss: 0.3480, Acc: 0.90\n",
            "Step [6400/50000], Loss: 0.3203, Acc: 0.90\n",
            "Step [6500/50000], Loss: 0.3731, Acc: 0.93\n",
            "Step [6600/50000], Loss: 0.4952, Acc: 0.90\n",
            "Step [6700/50000], Loss: 0.3506, Acc: 0.93\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step [6800/50000], Loss: 0.3995, Acc: 0.86\n",
            "Step [6900/50000], Loss: 0.2302, Acc: 0.94\n",
            "Step [7000/50000], Loss: 0.4002, Acc: 0.92\n",
            "Step [7100/50000], Loss: 0.2658, Acc: 0.93\n",
            "Step [7200/50000], Loss: 0.2728, Acc: 0.91\n",
            "Step [7300/50000], Loss: 0.4588, Acc: 0.88\n",
            "Step [7400/50000], Loss: 0.3009, Acc: 0.92\n",
            "Step [7500/50000], Loss: 0.4464, Acc: 0.86\n",
            "Step [7600/50000], Loss: 0.4066, Acc: 0.89\n",
            "Step [7700/50000], Loss: 0.4005, Acc: 0.93\n",
            "Step [7800/50000], Loss: 0.4157, Acc: 0.89\n",
            "Step [7900/50000], Loss: 0.3094, Acc: 0.91\n",
            "Step [8000/50000], Loss: 0.3735, Acc: 0.90\n",
            "Step [8100/50000], Loss: 0.5349, Acc: 0.83\n",
            "Step [8200/50000], Loss: 0.3989, Acc: 0.92\n",
            "Step [8300/50000], Loss: 0.2864, Acc: 0.96\n",
            "Step [8400/50000], Loss: 0.2345, Acc: 0.93\n",
            "Step [8500/50000], Loss: 0.3184, Acc: 0.91\n",
            "Step [8600/50000], Loss: 0.3708, Acc: 0.90\n",
            "Step [8700/50000], Loss: 0.3492, Acc: 0.94\n",
            "Step [8800/50000], Loss: 0.3046, Acc: 0.94\n",
            "Step [8900/50000], Loss: 0.3306, Acc: 0.94\n",
            "Step [9000/50000], Loss: 0.3273, Acc: 0.92\n",
            "Step [9100/50000], Loss: 0.2754, Acc: 0.91\n",
            "Step [9200/50000], Loss: 0.2484, Acc: 0.93\n",
            "Step [9300/50000], Loss: 0.3179, Acc: 0.90\n",
            "Step [9400/50000], Loss: 0.4146, Acc: 0.90\n",
            "Step [9500/50000], Loss: 0.2734, Acc: 0.92\n",
            "Step [9600/50000], Loss: 0.3925, Acc: 0.88\n",
            "Step [9700/50000], Loss: 0.2747, Acc: 0.92\n",
            "Step [9800/50000], Loss: 0.3941, Acc: 0.88\n",
            "Step [9900/50000], Loss: 0.2308, Acc: 0.92\n",
            "Step [10000/50000], Loss: 0.2374, Acc: 0.94\n",
            "Step [10100/50000], Loss: 0.2356, Acc: 0.95\n",
            "Step [10200/50000], Loss: 0.2834, Acc: 0.92\n",
            "Step [10300/50000], Loss: 0.4010, Acc: 0.92\n",
            "Step [10400/50000], Loss: 0.2979, Acc: 0.93\n",
            "Step [10500/50000], Loss: 0.4430, Acc: 0.88\n",
            "Step [10600/50000], Loss: 0.3037, Acc: 0.93\n",
            "Step [10700/50000], Loss: 0.2768, Acc: 0.94\n",
            "Step [10800/50000], Loss: 0.1908, Acc: 0.95\n",
            "Step [10900/50000], Loss: 0.3323, Acc: 0.90\n",
            "Step [11000/50000], Loss: 0.2965, Acc: 0.91\n",
            "Step [11100/50000], Loss: 0.3011, Acc: 0.91\n",
            "Step [11200/50000], Loss: 0.2794, Acc: 0.91\n",
            "Step [11300/50000], Loss: 0.2925, Acc: 0.92\n",
            "Step [11400/50000], Loss: 0.3156, Acc: 0.90\n",
            "Step [11500/50000], Loss: 0.2379, Acc: 0.93\n",
            "Step [11600/50000], Loss: 0.3748, Acc: 0.92\n",
            "Step [11700/50000], Loss: 0.2604, Acc: 0.91\n",
            "Step [11800/50000], Loss: 0.1887, Acc: 0.94\n",
            "Step [11900/50000], Loss: 0.3556, Acc: 0.90\n",
            "Step [12000/50000], Loss: 0.4105, Acc: 0.86\n",
            "Step [12100/50000], Loss: 0.2596, Acc: 0.91\n",
            "Step [12200/50000], Loss: 0.2793, Acc: 0.92\n",
            "Step [12300/50000], Loss: 0.1996, Acc: 0.95\n",
            "Step [12400/50000], Loss: 0.1887, Acc: 0.94\n",
            "Step [12500/50000], Loss: 0.2374, Acc: 0.93\n",
            "Step [12600/50000], Loss: 0.3291, Acc: 0.89\n",
            "Step [12700/50000], Loss: 0.3137, Acc: 0.90\n",
            "Step [12800/50000], Loss: 0.2957, Acc: 0.90\n",
            "Step [12900/50000], Loss: 0.3314, Acc: 0.90\n",
            "Step [13000/50000], Loss: 0.2819, Acc: 0.93\n",
            "Step [13100/50000], Loss: 0.1795, Acc: 0.95\n",
            "Step [13200/50000], Loss: 0.2312, Acc: 0.95\n",
            "Step [13300/50000], Loss: 0.2692, Acc: 0.89\n",
            "Step [13400/50000], Loss: 0.2185, Acc: 0.94\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step [13500/50000], Loss: 0.2230, Acc: 0.91\n",
            "Step [13600/50000], Loss: 0.3812, Acc: 0.90\n",
            "Step [13700/50000], Loss: 0.3054, Acc: 0.93\n",
            "Step [13800/50000], Loss: 0.2774, Acc: 0.92\n",
            "Step [13900/50000], Loss: 0.2062, Acc: 0.93\n",
            "Step [14000/50000], Loss: 0.2969, Acc: 0.93\n",
            "Step [14100/50000], Loss: 0.2161, Acc: 0.95\n",
            "Step [14200/50000], Loss: 0.2564, Acc: 0.91\n",
            "Step [14300/50000], Loss: 0.1721, Acc: 0.96\n",
            "Step [14400/50000], Loss: 0.2300, Acc: 0.91\n",
            "Step [14500/50000], Loss: 0.3334, Acc: 0.88\n",
            "Step [14600/50000], Loss: 0.3109, Acc: 0.90\n",
            "Step [14700/50000], Loss: 0.2670, Acc: 0.92\n",
            "Step [14800/50000], Loss: 0.2356, Acc: 0.93\n",
            "Step [14900/50000], Loss: 0.3205, Acc: 0.93\n",
            "Step [15000/50000], Loss: 0.1490, Acc: 0.96\n",
            "Step [15100/50000], Loss: 0.2802, Acc: 0.91\n",
            "Step [15200/50000], Loss: 0.2737, Acc: 0.93\n",
            "Step [15300/50000], Loss: 0.1788, Acc: 0.95\n",
            "Step [15400/50000], Loss: 0.1793, Acc: 0.96\n",
            "Step [15500/50000], Loss: 0.2460, Acc: 0.92\n",
            "Step [15600/50000], Loss: 0.1833, Acc: 0.96\n",
            "Step [15700/50000], Loss: 0.1473, Acc: 0.96\n",
            "Step [15900/50000], Loss: 0.2441, Acc: 0.94\n",
            "Step [16000/50000], Loss: 0.2714, Acc: 0.93\n",
            "Step [16100/50000], Loss: 0.1502, Acc: 0.97\n",
            "Step [16200/50000], Loss: 0.1766, Acc: 0.95\n",
            "Step [16300/50000], Loss: 0.3049, Acc: 0.94\n",
            "Step [16400/50000], Loss: 0.2728, Acc: 0.91\n",
            "Step [16500/50000], Loss: 0.2477, Acc: 0.94\n",
            "Step [16600/50000], Loss: 0.2213, Acc: 0.95\n",
            "Step [16700/50000], Loss: 0.2286, Acc: 0.92\n",
            "Step [16800/50000], Loss: 0.2747, Acc: 0.92\n",
            "Step [16900/50000], Loss: 0.2955, Acc: 0.92\n",
            "Step [17000/50000], Loss: 0.2269, Acc: 0.94\n",
            "Step [17100/50000], Loss: 0.2222, Acc: 0.95\n",
            "Step [17200/50000], Loss: 0.2259, Acc: 0.92\n",
            "Step [17300/50000], Loss: 0.2193, Acc: 0.90\n",
            "Step [17400/50000], Loss: 0.2275, Acc: 0.91\n",
            "Step [17500/50000], Loss: 0.1872, Acc: 0.93\n",
            "Step [17600/50000], Loss: 0.2110, Acc: 0.93\n",
            "Step [17700/50000], Loss: 0.2883, Acc: 0.94\n",
            "Step [17800/50000], Loss: 0.3044, Acc: 0.90\n",
            "Step [17900/50000], Loss: 0.2761, Acc: 0.94\n",
            "Step [18000/50000], Loss: 0.2673, Acc: 0.92\n",
            "Step [18100/50000], Loss: 0.2099, Acc: 0.93\n",
            "Step [18200/50000], Loss: 0.4108, Acc: 0.92\n",
            "Step [18300/50000], Loss: 0.2293, Acc: 0.95\n",
            "Step [18400/50000], Loss: 0.2057, Acc: 0.94\n",
            "Step [18500/50000], Loss: 0.2506, Acc: 0.90\n",
            "Step [18600/50000], Loss: 0.2303, Acc: 0.92\n",
            "Step [18700/50000], Loss: 0.1712, Acc: 0.96\n",
            "Step [18800/50000], Loss: 0.2804, Acc: 0.92\n",
            "Step [18900/50000], Loss: 0.1668, Acc: 0.95\n",
            "Step [19000/50000], Loss: 0.2292, Acc: 0.93\n",
            "Step [19100/50000], Loss: 0.3297, Acc: 0.91\n",
            "Step [19200/50000], Loss: 0.2947, Acc: 0.93\n",
            "Step [19300/50000], Loss: 0.4297, Acc: 0.86\n",
            "Step [19400/50000], Loss: 0.2739, Acc: 0.90\n",
            "Step [19500/50000], Loss: 0.2152, Acc: 0.96\n",
            "Step [19600/50000], Loss: 0.1865, Acc: 0.94\n",
            "Step [19700/50000], Loss: 0.1562, Acc: 0.95\n",
            "Step [19800/50000], Loss: 0.2141, Acc: 0.94\n",
            "Step [19900/50000], Loss: 0.2459, Acc: 0.93\n",
            "Step [20000/50000], Loss: 0.0875, Acc: 0.99\n",
            "Step [20100/50000], Loss: 0.1664, Acc: 0.95\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step [20200/50000], Loss: 0.1201, Acc: 0.97\n",
            "Step [20300/50000], Loss: 0.3037, Acc: 0.92\n",
            "Step [20400/50000], Loss: 0.2542, Acc: 0.95\n",
            "Step [20500/50000], Loss: 0.2016, Acc: 0.93\n",
            "Step [20600/50000], Loss: 0.1150, Acc: 0.97\n",
            "Step [20700/50000], Loss: 0.2134, Acc: 0.93\n",
            "Step [20800/50000], Loss: 0.2322, Acc: 0.92\n",
            "Step [20900/50000], Loss: 0.1703, Acc: 0.96\n",
            "Step [21000/50000], Loss: 0.2530, Acc: 0.90\n",
            "Step [21100/50000], Loss: 0.1375, Acc: 0.96\n",
            "Step [21200/50000], Loss: 0.2048, Acc: 0.95\n",
            "Step [21300/50000], Loss: 0.1746, Acc: 0.96\n",
            "Step [21400/50000], Loss: 0.2453, Acc: 0.95\n",
            "Step [21500/50000], Loss: 0.1539, Acc: 0.98\n",
            "Step [21600/50000], Loss: 0.2388, Acc: 0.91\n",
            "Step [21700/50000], Loss: 0.2739, Acc: 0.91\n",
            "Step [21800/50000], Loss: 0.3101, Acc: 0.91\n",
            "Step [21900/50000], Loss: 0.2273, Acc: 0.91\n",
            "Step [22000/50000], Loss: 0.2275, Acc: 0.93\n",
            "Step [22100/50000], Loss: 0.2803, Acc: 0.90\n",
            "Step [22200/50000], Loss: 0.3033, Acc: 0.90\n",
            "Step [22300/50000], Loss: 0.2143, Acc: 0.96\n",
            "Step [22400/50000], Loss: 0.1619, Acc: 0.96\n",
            "Step [22500/50000], Loss: 0.2872, Acc: 0.92\n",
            "Step [22600/50000], Loss: 0.2519, Acc: 0.93\n",
            "Step [22700/50000], Loss: 0.3305, Acc: 0.91\n",
            "Step [22800/50000], Loss: 0.1436, Acc: 0.96\n",
            "Step [22900/50000], Loss: 0.1766, Acc: 0.96\n",
            "Step [23000/50000], Loss: 0.3787, Acc: 0.92\n",
            "Step [23100/50000], Loss: 0.1731, Acc: 0.94\n",
            "Step [23200/50000], Loss: 0.2554, Acc: 0.96\n",
            "Step [23300/50000], Loss: 0.1936, Acc: 0.94\n",
            "Step [23400/50000], Loss: 0.1548, Acc: 0.96\n",
            "Step [23500/50000], Loss: 0.2334, Acc: 0.91\n",
            "Step [23600/50000], Loss: 0.3163, Acc: 0.90\n",
            "Step [23700/50000], Loss: 0.2298, Acc: 0.93\n",
            "Step [23800/50000], Loss: 0.2367, Acc: 0.92\n",
            "Step [23900/50000], Loss: 0.2962, Acc: 0.91\n",
            "Step [24000/50000], Loss: 0.1162, Acc: 0.98\n",
            "Step [24100/50000], Loss: 0.1999, Acc: 0.95\n",
            "Step [24200/50000], Loss: 0.2027, Acc: 0.92\n",
            "Step [24300/50000], Loss: 0.2591, Acc: 0.92\n",
            "Step [24400/50000], Loss: 0.2111, Acc: 0.95\n",
            "Step [24500/50000], Loss: 0.3199, Acc: 0.92\n",
            "Step [24600/50000], Loss: 0.2778, Acc: 0.95\n",
            "Step [24700/50000], Loss: 0.1438, Acc: 0.96\n",
            "Step [24800/50000], Loss: 0.2325, Acc: 0.92\n",
            "Step [24900/50000], Loss: 0.1691, Acc: 0.95\n",
            "Step [25000/50000], Loss: 0.0852, Acc: 1.00\n",
            "Step [25100/50000], Loss: 0.2439, Acc: 0.93\n",
            "Step [25200/50000], Loss: 0.1592, Acc: 0.96\n",
            "Step [25300/50000], Loss: 0.1333, Acc: 0.95\n",
            "Step [25400/50000], Loss: 0.2205, Acc: 0.96\n",
            "Step [25500/50000], Loss: 0.1919, Acc: 0.95\n",
            "Step [25600/50000], Loss: 0.1119, Acc: 0.98\n",
            "Step [25700/50000], Loss: 0.2419, Acc: 0.93\n",
            "Step [25800/50000], Loss: 0.1643, Acc: 0.94\n",
            "Step [25900/50000], Loss: 0.1597, Acc: 0.96\n",
            "Step [26000/50000], Loss: 0.1595, Acc: 0.96\n",
            "Step [26100/50000], Loss: 0.0923, Acc: 0.99\n",
            "Step [26200/50000], Loss: 0.1612, Acc: 0.95\n",
            "Step [26300/50000], Loss: 0.2338, Acc: 0.94\n",
            "Step [26400/50000], Loss: 0.1968, Acc: 0.95\n",
            "Step [26500/50000], Loss: 0.1756, Acc: 0.93\n",
            "Step [26600/50000], Loss: 0.1103, Acc: 0.99\n",
            "Step [26700/50000], Loss: 0.2974, Acc: 0.91\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step [26800/50000], Loss: 0.1420, Acc: 0.97\n",
            "Step [26900/50000], Loss: 0.2654, Acc: 0.91\n",
            "Step [27000/50000], Loss: 0.1850, Acc: 0.96\n",
            "Step [27100/50000], Loss: 0.2077, Acc: 0.94\n",
            "Step [27200/50000], Loss: 0.2682, Acc: 0.91\n",
            "Step [27300/50000], Loss: 0.1161, Acc: 0.97\n",
            "Step [27400/50000], Loss: 0.2050, Acc: 0.91\n",
            "Step [27500/50000], Loss: 0.1329, Acc: 0.98\n",
            "Step [27600/50000], Loss: 0.2937, Acc: 0.93\n",
            "Step [27700/50000], Loss: 0.1610, Acc: 0.94\n",
            "Step [27800/50000], Loss: 0.0931, Acc: 0.97\n",
            "Step [27900/50000], Loss: 0.2165, Acc: 0.94\n",
            "Step [28000/50000], Loss: 0.1277, Acc: 0.97\n",
            "Step [28100/50000], Loss: 0.1055, Acc: 0.97\n",
            "Step [28200/50000], Loss: 0.2992, Acc: 0.90\n",
            "Step [28300/50000], Loss: 0.1816, Acc: 0.97\n",
            "Step [28400/50000], Loss: 0.2448, Acc: 0.92\n",
            "Step [28500/50000], Loss: 0.2253, Acc: 0.93\n",
            "Step [28600/50000], Loss: 0.2175, Acc: 0.94\n",
            "Step [28700/50000], Loss: 0.1308, Acc: 0.97\n",
            "Step [28800/50000], Loss: 0.2453, Acc: 0.93\n",
            "Step [28900/50000], Loss: 0.2032, Acc: 0.92\n",
            "Step [29000/50000], Loss: 0.1536, Acc: 0.94\n",
            "Step [29100/50000], Loss: 0.1386, Acc: 0.94\n",
            "Step [29200/50000], Loss: 0.1565, Acc: 0.97\n",
            "Step [29300/50000], Loss: 0.1705, Acc: 0.95\n",
            "Step [29400/50000], Loss: 0.1199, Acc: 0.97\n",
            "Step [29500/50000], Loss: 0.1137, Acc: 0.98\n",
            "Step [29600/50000], Loss: 0.2683, Acc: 0.93\n",
            "Step [29700/50000], Loss: 0.1279, Acc: 0.97\n",
            "Step [29800/50000], Loss: 0.2751, Acc: 0.90\n",
            "Step [29900/50000], Loss: 0.2766, Acc: 0.92\n",
            "Step [30000/50000], Loss: 0.1962, Acc: 0.95\n",
            "Step [30100/50000], Loss: 0.3136, Acc: 0.92\n",
            "Step [30200/50000], Loss: 0.2371, Acc: 0.93\n",
            "Step [30300/50000], Loss: 0.2193, Acc: 0.95\n",
            "Step [30400/50000], Loss: 0.2271, Acc: 0.92\n",
            "Step [30500/50000], Loss: 0.2370, Acc: 0.93\n",
            "Step [30600/50000], Loss: 0.2040, Acc: 0.92\n",
            "Step [30700/50000], Loss: 0.1705, Acc: 0.94\n",
            "Step [30800/50000], Loss: 0.2397, Acc: 0.90\n",
            "Step [30900/50000], Loss: 0.1802, Acc: 0.92\n",
            "Step [31000/50000], Loss: 0.0980, Acc: 0.98\n",
            "Step [31100/50000], Loss: 0.2740, Acc: 0.93\n",
            "Step [31200/50000], Loss: 0.1724, Acc: 0.96\n",
            "Step [31300/50000], Loss: 0.1858, Acc: 0.95\n",
            "Step [31400/50000], Loss: 0.1385, Acc: 0.96\n",
            "Step [31500/50000], Loss: 0.0828, Acc: 0.98\n",
            "Step [31600/50000], Loss: 0.1377, Acc: 0.98\n",
            "Step [31700/50000], Loss: 0.0555, Acc: 0.99\n",
            "Step [31800/50000], Loss: 0.1720, Acc: 0.96\n",
            "Step [31900/50000], Loss: 0.1461, Acc: 0.97\n",
            "Step [32000/50000], Loss: 0.2493, Acc: 0.94\n",
            "Step [32100/50000], Loss: 0.1301, Acc: 0.98\n",
            "Step [32200/50000], Loss: 0.1508, Acc: 0.96\n",
            "Step [32300/50000], Loss: 0.1097, Acc: 0.96\n",
            "Step [32400/50000], Loss: 0.1115, Acc: 0.97\n",
            "Step [32500/50000], Loss: 0.1682, Acc: 0.95\n",
            "Step [32600/50000], Loss: 0.1067, Acc: 0.99\n",
            "Step [32700/50000], Loss: 0.2316, Acc: 0.93\n",
            "Step [32800/50000], Loss: 0.1865, Acc: 0.93\n",
            "Step [32900/50000], Loss: 0.2396, Acc: 0.91\n",
            "Step [33000/50000], Loss: 0.1760, Acc: 0.92\n",
            "Step [33100/50000], Loss: 0.1484, Acc: 0.96\n",
            "Step [33200/50000], Loss: 0.1309, Acc: 0.97\n",
            "Step [33300/50000], Loss: 0.2374, Acc: 0.90\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step [33400/50000], Loss: 0.0992, Acc: 0.98\n",
            "Step [33500/50000], Loss: 0.3224, Acc: 0.92\n",
            "Step [33600/50000], Loss: 0.1580, Acc: 0.96\n",
            "Step [33700/50000], Loss: 0.1622, Acc: 0.94\n",
            "Step [33800/50000], Loss: 0.1429, Acc: 0.98\n",
            "Step [33900/50000], Loss: 0.1329, Acc: 0.96\n",
            "Step [34000/50000], Loss: 0.1529, Acc: 0.97\n",
            "Step [34100/50000], Loss: 0.1233, Acc: 0.96\n",
            "Step [34200/50000], Loss: 0.2140, Acc: 0.94\n",
            "Step [34300/50000], Loss: 0.0941, Acc: 0.99\n",
            "Step [34400/50000], Loss: 0.1997, Acc: 0.95\n",
            "Step [34500/50000], Loss: 0.1154, Acc: 0.98\n",
            "Step [34600/50000], Loss: 0.1001, Acc: 0.97\n",
            "Step [34700/50000], Loss: 0.1284, Acc: 0.94\n",
            "Step [34800/50000], Loss: 0.1793, Acc: 0.93\n",
            "Step [34900/50000], Loss: 0.2286, Acc: 0.94\n",
            "Step [35000/50000], Loss: 0.1942, Acc: 0.94\n",
            "Step [35100/50000], Loss: 0.1157, Acc: 0.98\n",
            "Step [35200/50000], Loss: 0.1693, Acc: 0.95\n",
            "Step [35300/50000], Loss: 0.1591, Acc: 0.95\n",
            "Step [35400/50000], Loss: 0.0901, Acc: 0.98\n",
            "Step [35500/50000], Loss: 0.1880, Acc: 0.96\n",
            "Step [35600/50000], Loss: 0.2035, Acc: 0.95\n",
            "Step [35700/50000], Loss: 0.0727, Acc: 0.98\n",
            "Step [35800/50000], Loss: 0.1393, Acc: 0.94\n",
            "Step [35900/50000], Loss: 0.2088, Acc: 0.94\n",
            "Step [36000/50000], Loss: 0.2068, Acc: 0.91\n",
            "Step [36100/50000], Loss: 0.1393, Acc: 0.96\n",
            "Step [36200/50000], Loss: 0.1192, Acc: 0.95\n",
            "Step [36300/50000], Loss: 0.0690, Acc: 0.98\n",
            "Step [36400/50000], Loss: 0.1764, Acc: 0.94\n",
            "Step [36500/50000], Loss: 0.0758, Acc: 0.99\n",
            "Step [36600/50000], Loss: 0.1971, Acc: 0.96\n",
            "Step [36700/50000], Loss: 0.1039, Acc: 0.98\n",
            "Step [36800/50000], Loss: 0.1425, Acc: 0.96\n",
            "Step [36900/50000], Loss: 0.2074, Acc: 0.90\n",
            "Step [37000/50000], Loss: 0.2084, Acc: 0.93\n",
            "Step [37100/50000], Loss: 0.1247, Acc: 0.96\n",
            "Step [37200/50000], Loss: 0.1245, Acc: 0.96\n",
            "Step [37300/50000], Loss: 0.1162, Acc: 0.96\n",
            "Step [37400/50000], Loss: 0.2550, Acc: 0.93\n",
            "Step [37500/50000], Loss: 0.0995, Acc: 0.97\n",
            "Step [37600/50000], Loss: 0.2279, Acc: 0.95\n",
            "Step [37700/50000], Loss: 0.1445, Acc: 0.95\n",
            "Step [37800/50000], Loss: 0.1749, Acc: 0.95\n",
            "Step [37900/50000], Loss: 0.1284, Acc: 0.97\n",
            "Step [38000/50000], Loss: 0.2748, Acc: 0.91\n",
            "Step [38100/50000], Loss: 0.1870, Acc: 0.96\n",
            "Step [38200/50000], Loss: 0.1298, Acc: 0.96\n",
            "Step [38300/50000], Loss: 0.2628, Acc: 0.90\n",
            "Step [38400/50000], Loss: 0.1513, Acc: 0.95\n",
            "Step [38500/50000], Loss: 0.1215, Acc: 0.97\n",
            "Step [38600/50000], Loss: 0.1706, Acc: 0.94\n",
            "Step [38700/50000], Loss: 0.1991, Acc: 0.90\n",
            "Step [38800/50000], Loss: 0.1564, Acc: 0.96\n",
            "Step [38900/50000], Loss: 0.1883, Acc: 0.94\n",
            "Step [39000/50000], Loss: 0.1491, Acc: 0.96\n",
            "Step [39100/50000], Loss: 0.2353, Acc: 0.90\n",
            "Step [39200/50000], Loss: 0.1694, Acc: 0.93\n",
            "Step [39300/50000], Loss: 0.1585, Acc: 0.95\n",
            "Step [39400/50000], Loss: 0.1744, Acc: 0.94\n",
            "Step [39500/50000], Loss: 0.2521, Acc: 0.94\n",
            "Step [39600/50000], Loss: 0.0680, Acc: 0.99\n",
            "Step [39700/50000], Loss: 0.1011, Acc: 0.96\n",
            "Step [39800/50000], Loss: 0.0951, Acc: 0.97\n",
            "Step [39900/50000], Loss: 0.2139, Acc: 0.93\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step [40000/50000], Loss: 0.2912, Acc: 0.90\n",
            "Step [40100/50000], Loss: 0.1567, Acc: 0.96\n",
            "Step [40200/50000], Loss: 0.1580, Acc: 0.99\n",
            "Step [40300/50000], Loss: 0.1925, Acc: 0.94\n",
            "Step [40400/50000], Loss: 0.1399, Acc: 0.97\n",
            "Step [40500/50000], Loss: 0.1548, Acc: 0.93\n",
            "Step [40600/50000], Loss: 0.1789, Acc: 0.94\n",
            "Step [40700/50000], Loss: 0.1674, Acc: 0.96\n",
            "Step [40800/50000], Loss: 0.1749, Acc: 0.96\n",
            "Step [40900/50000], Loss: 0.1456, Acc: 0.98\n",
            "Step [41000/50000], Loss: 0.1054, Acc: 0.98\n",
            "Step [41100/50000], Loss: 0.1460, Acc: 0.96\n",
            "Step [41200/50000], Loss: 0.0542, Acc: 0.99\n",
            "Step [41300/50000], Loss: 0.0508, Acc: 1.00\n",
            "Step [41400/50000], Loss: 0.0664, Acc: 0.98\n",
            "Step [41500/50000], Loss: 0.1781, Acc: 0.96\n",
            "Step [41600/50000], Loss: 0.1315, Acc: 0.94\n",
            "Step [41700/50000], Loss: 0.1522, Acc: 0.95\n",
            "Step [41800/50000], Loss: 0.1334, Acc: 0.97\n",
            "Step [41900/50000], Loss: 0.0678, Acc: 0.98\n",
            "Step [42000/50000], Loss: 0.1663, Acc: 0.95\n",
            "Step [42100/50000], Loss: 0.2034, Acc: 0.93\n",
            "Step [42200/50000], Loss: 0.0643, Acc: 0.99\n",
            "Step [42300/50000], Loss: 0.2045, Acc: 0.93\n",
            "Step [42400/50000], Loss: 0.1274, Acc: 0.97\n",
            "Step [42500/50000], Loss: 0.1350, Acc: 0.97\n",
            "Step [42600/50000], Loss: 0.0937, Acc: 0.97\n",
            "Step [42700/50000], Loss: 0.1049, Acc: 0.97\n",
            "Step [42800/50000], Loss: 0.1074, Acc: 0.97\n",
            "Step [42900/50000], Loss: 0.1001, Acc: 0.96\n",
            "Step [43000/50000], Loss: 0.2467, Acc: 0.94\n",
            "Step [43100/50000], Loss: 0.2089, Acc: 0.93\n",
            "Step [43200/50000], Loss: 0.1684, Acc: 0.93\n",
            "Step [43300/50000], Loss: 0.1739, Acc: 0.95\n",
            "Step [43400/50000], Loss: 0.1304, Acc: 0.95\n",
            "Step [43500/50000], Loss: 0.1253, Acc: 0.95\n",
            "Step [43600/50000], Loss: 0.1170, Acc: 0.96\n",
            "Step [43700/50000], Loss: 0.1081, Acc: 0.97\n",
            "Step [43800/50000], Loss: 0.0867, Acc: 0.98\n",
            "Step [43900/50000], Loss: 0.1579, Acc: 0.94\n",
            "Step [44000/50000], Loss: 0.0834, Acc: 0.98\n",
            "Step [44100/50000], Loss: 0.1077, Acc: 0.97\n",
            "Step [44200/50000], Loss: 0.1746, Acc: 0.97\n",
            "Step [44300/50000], Loss: 0.1249, Acc: 0.99\n",
            "Step [44400/50000], Loss: 0.2456, Acc: 0.93\n",
            "Step [44500/50000], Loss: 0.2063, Acc: 0.95\n",
            "Step [44600/50000], Loss: 0.2086, Acc: 0.95\n",
            "Step [44700/50000], Loss: 0.0778, Acc: 0.99\n",
            "Step [44800/50000], Loss: 0.1545, Acc: 0.96\n",
            "Step [44900/50000], Loss: 0.1060, Acc: 0.96\n",
            "Step [45000/50000], Loss: 0.1376, Acc: 0.95\n",
            "Step [45100/50000], Loss: 0.1224, Acc: 0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cjkz_BKluX7s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}